{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af83cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from centigrad.network import Network\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e638d5a6",
   "metadata": {},
   "source": [
    "# Usage example 1\n",
    "\n",
    "- The XoR problem is a classic problem that I first encountered while reading **Goodfellow, Ian, Bengio, Yoshua, & Courville, Aaron.** (2016). *Deep Learning*. MIT Press. [http://www.deeplearningbook.org](http://www.deeplearningbook.org)\n",
    "\n",
    "- Convergence with random intialization is not guaranteed in the XoR problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0, 1, 1],\n",
    "       [0, 1, 0, 1]])\n",
    "y = np.array([[0, 1, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Network(input_dim = 2,\n",
    "             layers_widths = [2, 1], \n",
    "             layers_activations = [\"relu\", \"linear\"])\n",
    "nn.fit(X, y, epochs = 1000, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial loss:\", \"{:.20f}\".format(nn.epoch_losses[0]))\n",
    "print(f\"Final loss after {len(nn.epoch_losses)-1} epocs:\", \"{:.20f}\".format(nn.epoch_losses[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7b095d",
   "metadata": {},
   "source": [
    "# Usage example 2\n",
    "\n",
    "- Linear regression for the XoR problem solving a NN with no activation and normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and Y\n",
    "X = np.array([[0, 0],\n",
    "              [0 ,1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "Y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc341ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including a column of 1s\n",
    "normal_eq_solution = np.matmul(np.linalg.inv(np.matmul(X_ols.T, X_ols)), np.matmul(X_ols.T, Y))\n",
    "print(f\"\"\"The linear regression solution solving normal equations to the XoR problem is:\n",
    "  b0: {normal_eq_solution[0][0]}\n",
    "  b1: {normal_eq_solution[1][0]}\n",
    "  b2: {normal_eq_solution[2][0]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c59af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Network(input_dim = 2,\n",
    "             layers_widths = [1], \n",
    "             layers_activations = [\"linear\"])\n",
    "nn.fit(X.T, y.T, epochs = 1000, learning_rate = 0.01)\n",
    "print(f\"\"\"The NN solution with no activation function is:\n",
    "  b0: {nn.layers[0].biases[0][0].value:.4f}\n",
    "  b1: {nn.layers[0].weights[0][0].value:.4f}\n",
    "  b2: {nn.layers[0].weights[1][0].value:.4f}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centigrad",
   "language": "python",
   "name": "centigrad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
